# -*- coding: utf-8 -*-
"""Notebook.pynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jbXrvLLq961giDllQp5WR9xeaarj7q4c

###**IMPORT DELLE DIPENDENZE**
"""

import numpy as np
import tensorflow
from tensorflow import keras
from keras.models import Sequential
from keras.callbacks import ModelCheckpoint
from keras.layers import Conv1D,Dense,Activation,BatchNormalization,MaxPooling1D,AveragePooling1D,Dropout,GlobalAveragePooling1D,Flatten
import pandas as pd

from sklearn.model_selection import StratifiedKFold,KFold
from sklearn.model_selection import train_test_split
from matplotlib import pyplot as plt
from sklearn.metrics import confusion_matrix as conf_matrix
from sklearn.metrics import classification_report
import keras.backend as K

"""###**FUNZIONI PER IL CARICAMENTO DEL DATASET**"""

def load_ECGs(path= "/content/drive/My Drive/ECGs/end_dataset-15.csv",propTrain = 0.5,propTest = 0.4):
    dataset = pd.read_csv(path)
    xLearning,xTest,yLearning,yTest = process_ECGDATA(dataset)
    xLearning,yLearning = balance(propTrain,xLearning,yLearning)
    xTest,yTest = balance(propTest,xTest,yTest)
    return xLearning,xTest,yLearning,yTest




def balance(propA,xTest,yTest):
  n=len(xTest)
  numN=num_labels(yTest,0)
  numA=num_labels(yTest,1)
  print('numero di A prima',numA)
  print('numero di N prima',numN)
  aPropN=numN/n
  aPropA=numA/n
  while aPropA>propA :
    for row in range(len(yTest)):
      if yTest[row]==1 :
        xTest=np.delete(xTest, row, 0)
        yTest=np.delete(yTest, row, 0)
        break
    numA=num_labels(yTest,1)
    n-=1
    aPropA=numA/n
  
  print('numero di A Dopo',num_labels(yTest,1))
  print('numero di N Dopo',num_labels(yTest,0))
  print('xTest',xTest)
  print('yTest',yTest)

  return xTest,yTest


def process_ECGDATA(data:pd.DataFrame,test_size=0.3):
   
    y = data['label']
    x=data.drop(["label"],axis=1)
   
 
    #converto on array
    x = np.asarray(x,dtype=np.float32)
    y = np.asarray(y)
    
    y = mapvalues(y,{'N':0,'A':1})
    
    y = np.asarray(y,dtype=np.float32)
    
    print("ECG segment Normal (N) ",num_labels(y,0))
    print("ECG segment Anormal (A) ",num_labels(y,1))
    
    
    xLearning,xTest,yLearning,yTest = train_test_split(x,y,test_size= test_size)
    
    return xLearning,xTest,yLearning,yTest


def num_labels(data,label):
    num = 0
    for value in data:
        if(value == label):
             num += 1
    return num


def showConfusionMatrix(y_test,y_pred):
    
    print("Confusion Matrix")
    matrix = conf_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))
    
    fig, ax = plt.subplots(figsize=(2.5, 2.5))
    ax.matshow(matrix, cmap=plt.cm.Blues, alpha=0.3)
    for i in range(matrix.shape[0]):
        for j in range(matrix.shape[1]):
            ax.text(x=j, y=i, s=matrix[i, j], va='center', ha='center')

    plt.xlabel('predicted label')
    plt.ylabel('true label')

    plt.tight_layout()
    plt.show() 

    print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1),target_names = ['N','A']))

    
    
    return matrix


def mapvalues(y:np.array,mapping:dict):
    y_bin = []
    for y_i in y:
        y_bin.append(mapping[y_i])
    return y_bin

"""###**CNN CON IPERPARAMETRI**"""

#Parametres
#-----------------------------------  

BATCH_SIZE = 54
EPOCHS = 200


def createCNN():
   n_classes = 2
   cnn = Sequential()
   cnn.add(Conv1D(128, kernel_size=80 ,strides=8,input_shape=(5400,1)))
   cnn.add(BatchNormalization())
   cnn.add(MaxPooling1D(pool_size=4))
   cnn.add(Activation('relu'))

   
   
   cnn.add(Conv1D(256,kernel_size=4))
   cnn.add(BatchNormalization())
   cnn.add(MaxPooling1D(pool_size=4))
   cnn.add(Activation('relu'))

   cnn.add(Conv1D(256,kernel_size=4))
   cnn.add(BatchNormalization())
   cnn.add(MaxPooling1D(pool_size=4))
   cnn.add(Activation('relu'))



   cnn.add(Conv1D(512,kernel_size=2))
   cnn.add(BatchNormalization())
   cnn.add(MaxPooling1D(pool_size=4))
   cnn.add(Activation('relu'))



   cnn.add(AveragePooling1D(pool_size=2))
   cnn.add(Flatten())
   cnn.add(Dropout(0.6))
   cnn.add(Dense(n_classes,kernel_regularizer=keras.regularizers.l2(0.001),activation='softmax'))
   cnn.compile(optimizer=tensorflow.keras.optimizers.Adamax(lr = 6.5e-6), loss='binary_crossentropy', metrics=['accuracy',tensorflow.keras.metrics.Recall(name ='recall')])

   return cnn


createCNN().summary()

"""##**FUNZIONI PER VALIDATION ETEST**"""

def validation(LearningX,LearningY,save_dir,K = 5,test_size = 0.1,batch_size= 128,epochs=50):
    
    #data
    
    n_classes = 2
    
    
    
    LearningX = LearningX.reshape(LearningX.shape[0], LearningX.shape[1],1)

    
    #to categorical
    LearningY = keras.utils.to_categorical(LearningY, n_classes)
    
    
    
    # Define the K-fold Cross Validator
    kfold = KFold(n_splits=K, shuffle=True)
    
    
    # K-fold Cross Validation model evaluation
    
    
    fold_no = 1
    
    ACCURACY=[]
    LOSSLESS=[]
    RECALL = []
  
    for train, val in kfold.split(LearningX,LearningY):
        model = createCNN()

        trainingSet_X = LearningX[train]
        trainingSet_y = LearningY[train]

        validation_X  = LearningX[val]
        validation_Y  = LearningY[val]

        print("New Iteration , K = " + fold_no.__str__())
        print("num N ( Normal ) on tuning:" + str(num_labels(validation_Y.argmax(axis=1),0)))
        print("num A (Anormal)  on tuning:" + str(num_labels(validation_Y.argmax(axis=1),1)))

        print("num N ( Normal ) on training:" + str(num_labels(trainingSet_y.argmax(axis=1),0)))
        print("num A (Anormal)  on training:" + str(num_labels(trainingSet_y.argmax(axis=1),1)))
        
        
        
        
        
        # CREATE CALLBACKS
        #checpoint_dir = save_dir + '/model_' + str(fold_no) + '.h5'
        #checkpoint = ModelCheckpoint(checpoint_dir, monitor='val_recall', verbose=1, save_best_only=True, mode='max')
    
    
        history = model.fit(trainingSet_X, trainingSet_y,
              batch_size=batch_size,
              epochs=epochs,
              verbose=1,
              validation_data = (validation_X, validation_Y))
        
        
        #model.load_weights(checpoint_dir)
        
        loss,acc,recall = model.evaluate( validation_X, validation_Y,batch_size=batch_size, verbose=1)
        ACCURACY.append(acc)
        LOSSLESS.append(loss)
        RECALL.append(recall)
        
        print("Model Results: ")
        print("lossless =  " + str(loss))
        print("accuracy = " + str(acc))
        print("recall =  " + str(recall))
        
       
    
        # summarize history for loss
        print('Accuracy Graph')
        plt.plot(history.history['accuracy'])
        plt.plot(history.history['val_accuracy'])
        plt.title('models')
        plt.ylabel('accuracy')
        plt.xlabel('epoch')
        plt.legend(['training', 'validation'], loc='upper left')
        plt.show()
        print('lOSS Graph')
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('models')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['training', 'validation'], loc='upper left')
        plt.show()

        print('Recall Graph')
        plt.plot(history.history['recall'])
        plt.plot(history.history['val_recall'])
        plt.title('models')
        plt.ylabel('recall')
        plt.xlabel('epoch')
        plt.legend(['training', 'validation'], loc='upper left')
        plt.show()
        
        fold_no = fold_no + 1
    
        
    print('mean accuracy %.3f +/- %.3f' % (np.mean(ACCURACY),np.std(ACCURACY)))
    print('mean loss %.3f +/- %.3f' % (np.mean(LOSSLESS),np.std(LOSSLESS)))
    print('mean recall %.3f +/- %.3f' % (np.mean(RECALL),np.std(RECALL)))
    
def saveECGClassifications(xTest,yTrue,yPred,output_dir):
  examples = list(xTest.reshape(xTest.shape[0],xTest.shape[1]))
  yTrue = yTrue.argmax(axis = 1)
  yPred = yPred.argmax(axis = 1)
  example_list = []
  for i in range(len(yTrue)):
    example_list.append(list(examples[i]))
    example_list[i].append(yTrue[i])

  
  pred_1_true_1 = []
  pred_0_true_1 = []
  for  example,y_pred in zip(example_list,yPred):
    y_true = example[-1]
    if y_pred == 0 and y_true == 1:
        pred_0_true_1.append(example)
    elif y_pred == 1 and y_true == 1 : 
        pred_1_true_1.append(example)
  pd.DataFrame(data = pred_0_true_1,).to_csv(output_dir+ '/predN_trueA.csv',index =False)
  pd.DataFrame(data = pred_1_true_1,).to_csv(output_dir+ '/predA_trueA.csv',index =False)








def finalPrediction(LearningX,LearningY,TestX,TestY,model, save_dir,batch_size=128,epochs=10):
    n_classes = 2
    LearningX = LearningX.reshape(LearningX.shape[0], LearningX.shape[1],1)
    LearningY = keras.utils.to_categorical(LearningY, n_classes)
    print(TestX.shape)
    
    TestX = TestX.reshape(TestX.shape[0], TestX.shape[1],1)
    TestY = keras.utils.to_categorical(TestY, n_classes)


    #checpoint_dir = save_dir + '/final_model.h5'
    #checkpoint = ModelCheckpoint(checpoint_dir, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')

    history = model.fit(LearningX,LearningY,batch_size=batch_size,validation_split = 0.1,epochs=epochs, verbose=1)
    """
    print('Accuracy Graph')
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('models')
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['training', 'validation'], loc='upper left')
    plt.show()
    print('lOSS Graph')
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('models')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['training', 'validation'], loc='upper left')
    plt.show()

    print('Recall Graph')
    plt.plot(history.history['recall'])
    plt.plot(history.history['val_recall'])
    plt.title('models')
    plt.ylabel('recall')
    plt.xlabel('epoch')
    plt.legend(['training', 'validation'], loc='upper left')
    plt.show()
    """

    #model.load_weights(checpoint_dir)
    Ypred = model.predict(TestX)
    showConfusionMatrix(TestY,Ypred)
    model.save(save_dir + '/final_model')
    saveECGClassifications(TestX,TestY,Ypred,SAVE_DIR)

"""###**CARICAMENTO DEL DATASET**"""

print('loading dataset...')
d = xLearning,xTest,yLearning,yTest = load_ECGs()
print(d)
print('DONE')

"""###**VALIDAZIONE**"""

print("start validation")
SAVE_DIR = '/content/drive/My Drive/ECGs/save_directory_2'

validation(xLearning,yLearning,save_dir=SAVE_DIR,epochs=EPOCHS, K = 10,batch_size=BATCH_SIZE)

"""###Validazione 70% Training 30%Validation"""

def validation70_30(LearningX,LearningY):
    
    #data
    
    n_classes = 2
    
    
    
    LearningX = LearningX.reshape(LearningX.shape[0], LearningX.shape[1],1)

    
    #to categorical
    LearningY = keras.utils.to_categorical(LearningY, n_classes)
    
    
  
    
    model = createCNN()
    xTrain,xVal,yTrain,yVal = train_test_split(LearningX,LearningY,test_size= 0.3)

        
        
        
        
    # CREATE CALLBACKS
    #checpoint_dir = save_dir + '/model_' + str(fold_no) + '.h5'
    #checkpoint = ModelCheckpoint(checpoint_dir, monitor='val_recall', verbose=1, save_best_only=True, mode='max')
    
    
    history = model.fit(xTrain, yTrain,
              batch_size=54,
              epochs=200,
              verbose=1,
              validation_data = (xVal, yVal))
        
        
        #model.load_weights(checpoint_dir)
        
    loss,acc,recall = model.evaluate( xVal, yVal,batch_size=54, verbose=1)

    print("Model Results: ")
    print("lossless =  " + str(loss))
    print("accuracy = " + str(acc))
    print("recall =  " + str(recall))
        
       
    
    # summarize history for loss
    print('Accuracy Graph')
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('models')
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['training', 'validation'], loc='upper left')
    plt.show()
    print('lOSS Graph')
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('models')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['training', 'validation'], loc='upper left')
    plt.show()

    print('Recall Graph')
    plt.plot(history.history['recall'])
    plt.plot(history.history['val_recall'])
    plt.title('models')
    plt.ylabel('recall')
    plt.xlabel('epoch')
    plt.legend(['training', 'validation'], loc='upper left')
    plt.show()
        
  
    
validation70_30(xLearning,yLearning)

"""#**TEST**"""

#--------------------------------


SAVE_DIR = '/content/drive/My Drive/ECGs/save_directory_2'

print('PARAMS: ')
print('epochs = ',EPOCHS)
print('batch_size = ',BATCH_SIZE)  #numero di terazioni per ogni epoca dipnede da questo valore


print("start final prediction")
model = createCNN()
model.summary()
finalPrediction(xLearning,yLearning,xTest,yTest,model = model,save_dir = SAVE_DIR,epochs=EPOCHS,batch_size=BATCH_SIZE)

